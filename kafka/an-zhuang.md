## 安裝要求：
**系統：** Linux
**Java環境:** 推薦JAVA8
**Zookeeper**

使用Zookeeper 保存集羣的元數據信息和消費者信息

## kafka 常規配置
**broker.id**
每個broker 都需要一個標識符，使用broker.id 來表示。它的默認值是0,也可以被設置成其他任意整數。這個值在整個Kafka 集羣裏必須是唯一的。建議設置成與機器名具有相關性的整數，這樣在進行維護時，將ID號映射到機器名就沒那麼麻煩了。

**port**
使用配置樣本啓動kafka， 會監聽9092端口。不建議使用root權限啓動

**zookeeper.connect**
用於保存broker 元數據的Zookeeper 地址。該配置參數用冒號分隔的一組hostname:port/path 列表，每一部分的含義如下：
* hostname 是Zookeeper 服務器的機器名或IP地址;
* port 是Zookeeper 的客戶端連接端口;
* /path 是可選的Zookeeper 路徑，作爲Kafka 集羣的chroot 環境。如果不指定，默認使用根路徑。

如果chroot 路徑不存在，broker 會在啓動的時候創建。

> **爲什麼使用chroot 路徑**
在Kafka 集羣裏使用chroot 路徑是一種最佳實踐。Zookeeper 羣組可以共享給其他應用程序，即使還有其他Kafka 集羣存在，也不會產生衝突。最好是在配置文件裏指定一組Zookeeper 服務器，用分號把它們隔開。一旦有一個Zookeeper 服務器宕機，broker 可以連接到Zookeeper 羣組的另一個節點上。

**log.dirs**
Kafka 把所有消息都保存在磁盤上，存放這些日志片段的目錄是通過log.dirs 指定的。它是一組用逗號分隔的本地文件系統路徑。如果指定了多個路徑，那麼broker 會根據“最少使用”原則，把同一個分區的日志片段保存到同一個路徑下。要注意，broker 會往擁有最少數目分區的路徑新增分區，而不是往擁有最小磁盤空間的路徑新增分區。

**num.recovery.threads.per.data.dir**
對於如下3種情況，Kafka 會使用可配置的線程池來處理日志片段：
* 服務器正常啓動，用於打開每個分區的日志片段;
* 服務器崩潰後重啓，用於檢查和截短每個分區的日志片段;
* 服務器正常關閉，用於關閉日志片段。

這些線程只是在服務器啓動和關閉時會用到。默認每個日志目錄只使用一個線程。設置此參數時需要注意，所配置的數字對應的是log.dirs指定的單個日志目錄。總線程= *log.dir 指定路徑個數。

**auto.create.topics.enable**
默認情況，Kafka 會在如下幾種情形下自動創建主題：
* 當一個生產者開始往主題寫入消息時;
* 當一個消費者開始從主題讀取消息時;
* 當任意一個客戶端向主題發送元數據請求時。

**initLimit**表示用於在從節點與主節點之間建立初始化連接的時間上限，**syncLimit** 表示允許從節點與主節點處於不同步狀態的時間上限。這兩個值都是tickTime 的倍數，所以initLimit是20*2000ms，也就是40s。

服務器地址遵循server.X=hostname:peerPort:leaderPort 格式，參數說明如下：
**X** 服務器的ID，必須是一個整數，不過不一定要從0開始，也不要求是連續的;
**hostname** 服務器的機器名或IP地址;
**peerPort** 用於節點間通信的TCP端口;
**leaderPort** 用於首領選舉的TCP端口。

客戶端只需通過clientPort 就能連接到羣組，而羣組節點間的通信則需要同時用到這3個端口（peerPort、leaderPort、clientPort）。
每個服務器都必須在data DIR目錄中創建一個叫做myid的文件，文件裏要包含服務器ID，這個ID要與配置文件裏配置的ID 保持一致。

## 主題默認配置

1. num.partitions

num.partitions 參數指定了新創建的主題將包含多少個分區。自動創建主題，分區個數就是該參數指定的值。參數默認值是1。
可以增加主題分區個數，但不能減少分區的個數。手動創建主題，分區數可以少於num.partitions

擁有大量消息的主題如果要進行負載分散，就需要大量的分區。

> 如何選定分區數量
需要考慮如下因素
* 主題需要達到多大的吞吐量？例如，是希望每秒鍾寫入100KB還是1GB？
* 從單個分區讀取數據的最大吞吐量是多少？每個分區一般都會有一個消費者，如果你知道消費者將數據寫入數據庫的速度不會超過每秒50MB，那麼你也該知道，從一個分區讀取數據的吞吐量不需要超過每秒50MB。
* 可以通過類似的方法估算生產者向單個分區寫入數據的吞吐量，不過生產者的速度一般比消費者快得多，所以最好爲生產者多估算一些吞吐量。
* 每個broker 包含的分區個數、可用的磁盤空間和網絡帶寬。
* 如果消息是按照不同的鍵來寫入分區的，那麼爲已有的主題新增分區就會很困難。
* 單個broker 對分區個數是有限制的，因爲分區越多，佔用的內存越多，完成首領選舉需要的時間也越長。

如果你估算出主題的吞吐量和消費者吞吐量，可以用主題吞吐量除以消費者吞吐量算出分區的個數。也就是說，如果每秒鍾要從主題上寫入和讀取1GB的數據，並且每個消費者每秒鍾可以處理20MB的數據，那麼至少需要20個分區。這樣就可以讓20個消費者同時讀取這些分區，從而達到每秒鍾1GB的吞吐量。

**如果不知道這些信息，那麼根據經驗，把分區的大小限制在25GB以內可以得到比較理想的效果。**

2. log.retention.ms

Kafka 通常根據時間來決定數據可以被保留多久。默認使用log.retention.hours參數來配置時間，默認爲168小時，也就是一周。log.retention.minutes和log.retention.ms。這3個參數的作用是一樣的，推薦使用log.retention.ms。優先使用具有最小值的參數。

> **根據時間保留數據和最後修改時間**
根據時間保留數據是通過檢查磁盤上日志片段文件的最後修改時間來實現的。一般來說，最後修改時間指的就是日志片段的關閉時間，也就是文件裏最後一個消息的時間戳。

3. log.retention.bytes

另一種方式是通過保留的消息字節數來判斷消息是否過期。作業在每一個分區上，當主題的分區個數增加時，整個主題可以保留的數據也隨之增加。

> 根據字節大小和時間保留數據
如果同時指定了log.retention.bytes和log.retention.ms,只要任意一個條件得到滿足，消息就會被刪除。

4. log.segment.bytes

